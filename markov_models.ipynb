{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JL05y6BMQD0O"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IAT-ComputationalCreativity-Spring2025/Week3-Rule-Based-Systems/blob/main/markov_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaeE8L9kQD0P"
      },
      "source": [
        "# Markov Models Text Generation\n",
        "\n",
        "This notebook introduces Markov chains for text generation. We'll build a simple\n",
        "text generator that learns patterns from input text and generates new text with\n",
        "similar statistical properties."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "i84gAsMVQD0Q"
      },
      "outputs": [],
      "source": [
        "# First, let's import our required libraries\n",
        "from collections import defaultdict\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVQ4ZWabQD0Q"
      },
      "source": [
        "## Building the Markov Chain\n",
        "\n",
        "A Markov chain represents sequences of states where the probability of each state\n",
        "depends only on the previous state(s). In our case, each state will be a sequence\n",
        "of words, and we'll predict the next word based on this sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ez94MgQpQD0Q"
      },
      "outputs": [],
      "source": [
        "def build_markov_chain(text, order=2):\n",
        "    \"\"\"\n",
        "    Build a Markov chain from input text.\n",
        "\n",
        "    Args:\n",
        "        text (str): Input text to learn from\n",
        "        order (int): Number of words to use as state (context)\n",
        "\n",
        "    Returns:\n",
        "        dict: Mapping from state tuples to lists of possible next words\n",
        "    \"\"\"\n",
        "    chain = defaultdict(list)\n",
        "    words = text.split()\n",
        "\n",
        "    for i in range(len(words) - order):\n",
        "        # Create state tuple from current words\n",
        "        state = tuple(words[i:i+order])\n",
        "        # Get the next word\n",
        "        next_word = words[i+order]\n",
        "        # Add to chain\n",
        "        chain[state].append(next_word)\n",
        "\n",
        "    return chain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhuJEPkIQD0R"
      },
      "source": [
        "## Generating Text\n",
        "\n",
        "Now we'll use our Markov chain to generate new text. We'll randomly select from\n",
        "the possible next words at each step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Mt-Vg1y5QD0R"
      },
      "outputs": [],
      "source": [
        "def generate_text(chain, num_words=100): #changed num words to 100 for a story\n",
        "    \"\"\"\n",
        "    Generate new text using the Markov chain.\n",
        "\n",
        "    Args:\n",
        "        chain (dict): Markov chain mapping states to possible next words\n",
        "        order (int): Length of state tuples\n",
        "        num_words (int): Number of words to generate\n",
        "\n",
        "    Returns:\n",
        "        str: Generated text\n",
        "    \"\"\"\n",
        "    # Start with a random state from the chain\n",
        "    state = random.choice(list(chain.keys()))\n",
        "    words = list(random.choice(list(chain.keys())))\n",
        "    order = len(list(chain.keys())[0])\n",
        "\n",
        "    for _ in range(num_words - order):\n",
        "        state = tuple(words[-order:])\n",
        "        if state in chain:\n",
        "            next_word = random.choice(chain[state])\n",
        "            words.append(next_word)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return ' '.join(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make story with markov chain**"
      ],
      "metadata": {
        "id": "tkL_l6g7ikDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text_for_markov = \"\"\"\n",
        "Once upon a time, in a land of magic and wonder, there lived a brave knight who embarked on a quest to save the kingdom from a terrible curse. Along his journey, he met a wise wizard and a cunning thief. Together, they traveled through enchanted forests and over towering mountains. Their path was filled with peril and unexpected challenges. In the darkest hours, when hope seemed lost, the trio found strength in their friendship and determination. Ultimately, the brave knight faced the dark sorcerer who had cast a shadow over the realm, and with courage, they restored peace and harmony.\n",
        "\"\"\"\n",
        "\n",
        "chain_story = build_markov_chain(sample_text_for_markov, order=2)\n",
        "\n",
        "\n",
        "chain_story = build_markov_chain(sample_text_for_markov, order=2)\n",
        "\n",
        "def generate_story_with_markov(min_words=100):\n",
        "    \"\"\"\n",
        "    Generate a story using the Markov chain with a simple title.\n",
        "    \"\"\"\n",
        "    story_text = generate_text(chain_story, num_words=min_words)\n",
        "    formatted_story = \"Title: A Markov Tale\\n\\n\" + story_text\n",
        "    return formatted_story\n"
      ],
      "metadata": {
        "id": "wuag6RZBijOj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make grammar for the story **"
      ],
      "metadata": {
        "id": "TLeUZPIgi7G7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grammar = {\n",
        "    \"story\": [\"<title>\\n\\n<introduction>\\n\\n<conflict>\\n\\n<resolution>\"],\n",
        "    \"title\": [\"The Epic of the <character>\"],\n",
        "    \"introduction\": [\n",
        "        \"Once upon a time, in a <setting>, there lived a brave <character> known for <trait>.\",\n",
        "        \"In the mystical realm of <setting>, a courageous <character> embarked on a journey marked by <trait>.\"\n",
        "    ],\n",
        "    \"conflict\": [\n",
        "        \"One fateful day, a <obstacle> arose, threatening the peace of <setting>. The <character> had to face <challenge> to save their world.\",\n",
        "        \"However, darkness loomed when a <obstacle> disrupted the harmony of <setting>, forcing the <character> to confront an unforeseen <challenge>.\"\n",
        "    ],\n",
        "    \"resolution\": [\n",
        "        \"In the end, after a long and arduous journey filled with trials, the <character> triumphed over the <obstacle>, restoring balance to <setting>.\",\n",
        "        \"Ultimately, the <character>'s unwavering resolve led to the defeat of the <obstacle>, bringing hope and renewal to <setting>.\"\n",
        "    ],\n",
        "    \"character\": [\"knight\", \"wizard\", \"detective\", \"adventurer\", \"sorcerer\"],\n",
        "    \"setting\": [\"enchanted forest\", \"mysterious kingdom\", \"forgotten realm\", \"ancient city\", \"distant galaxy\"],\n",
        "    \"trait\": [\"unwavering bravery\", \"incredible wisdom\", \"boundless curiosity\", \"steadfast determination\"],\n",
        "    \"obstacle\": [\"menacing dragon\", \"cunning villain\", \"dark curse\", \"ruthless warlord\", \"sinister conspiracy\"],\n",
        "    \"challenge\": [\"a series of daunting trials\", \"a perilous journey across dangerous lands\", \"battles that tested the limits of their spirit\"]\n",
        "}"
      ],
      "metadata": {
        "id": "xf0l1vQNjBRl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Expandtion function"
      ],
      "metadata": {
        "id": "XCXm2atGjSML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def expand(symbol):\n",
        "    \"\"\"\n",
        "    Recursively expand a nonterminal symbol using our grammar rules.\n",
        "    \"\"\"\n",
        "    if symbol not in grammar:\n",
        "        return symbol\n",
        "    expansion = random.choice(grammar[symbol])\n",
        "    result = \"\"\n",
        "    i = 0\n",
        "    while i < len(expansion):\n",
        "        if expansion[i] == \"<\":\n",
        "            j = expansion.find(\">\", i)\n",
        "            if j == -1:\n",
        "                result += expansion[i]\n",
        "                i += 1\n",
        "            else:\n",
        "                key = expansion[i+1:j]\n",
        "                replacement = expand(key)\n",
        "                result += replacement\n",
        "                i = j + 1\n",
        "        else:\n",
        "            result += expansion[i]\n",
        "            i += 1\n",
        "    return result"
      ],
      "metadata": {
        "id": "UpghOO0sjcGs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate the story, including grammar"
      ],
      "metadata": {
        "id": "qdwjeEDxje7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_story_with_grammar(min_words=100):\n",
        "    \"\"\"\n",
        "    Generate a story using a simple generative grammar. Appends extra sentences\n",
        "    if the story doesn't meet the minimum word count.\n",
        "    \"\"\"\n",
        "    story = expand(\"story\")\n",
        "    # Ensure that the story is at least `min_words` long.\n",
        "    while len(story.split()) < min_words:\n",
        "        extra_sentence = random.choice([expand(\"introduction\"), expand(\"conflict\"), expand(\"resolution\")])\n",
        "        story += \"\\n\" + extra_sentence\n",
        "    return story\n"
      ],
      "metadata": {
        "id": "DANKsiAWjkyV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Print the story"
      ],
      "metadata": {
        "id": "Zma1enrZjp4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#print(\"=== Story Generated using Grammar ===\")\n",
        "#print(generate_story_with_grammar(min_words=100))\n",
        "print(\"\\n=== Story Generated using Markov Chain ===\")\n",
        "print(generate_story_with_markov(min_words=100))"
      ],
      "metadata": {
        "id": "KzUH7WUNliHN",
        "outputId": "46d67ebf-5ba8-49a7-f972-227fe8fc1d2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Story Generated using Markov Chain ===\n",
            "Title: A Markov Tale\n",
            "\n",
            "and wonder, there lived a brave knight who embarked on a quest to save the kingdom from a terrible curse. Along his journey, he met a wise wizard and a cunning thief. Together, they traveled through enchanted forests and over towering mountains. Their path was filled with peril and unexpected challenges. In the darkest hours, when hope seemed lost, the trio found strength in their friendship and determination. Ultimately, the brave knight faced the dark sorcerer who had cast a shadow over the realm, and with courage, they restored peace and harmony.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "84tbHUcyjA7t"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hkik5C2wQD0R"
      },
      "source": [
        "## Part 3: Basic Example\n",
        "\n",
        "Let's try our text generator with a simple example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fgJ7Jp4UQD0R",
        "outputId": "e60fb3fa-cf7d-4e19-d12d-ebba7b72f0af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skibidi rizz -> ['or']\n",
            "rizz or -> ['not']\n",
            "or not -> ['to']\n",
            "not to -> ['rizz,']\n",
            "to rizz, -> ['that']\n",
            "rizz, that -> ['is']\n",
            "that is -> ['the']\n",
            "is the -> ['giga-chad']\n",
            "the giga-chad -> ['question:']\n",
            "giga-chad question: -> ['Whether']\n",
            "question: Whether -> [\"'tis\"]\n",
            "Whether 'tis -> ['NPC-core']\n",
            "'tis NPC-core -> ['to']\n",
            "NPC-core to -> ['sigma']\n",
            "to sigma -> ['through']\n",
            "sigma through -> ['the']\n",
            "through the -> ['ratioed']\n",
            "the ratioed -> ['slings']\n",
            "ratioed slings -> ['and']\n",
            "slings and -> ['arrows']\n",
            "and arrows -> ['Of']\n",
            "arrows Of -> ['outrageous']\n",
            "Of outrageous -> ['fanum']\n",
            "outrageous fanum -> ['tax,']\n",
            "fanum tax, -> ['cap,']\n",
            "tax, cap, -> ['and']\n",
            "cap, and -> ['giga-Ls—']\n",
            "and giga-Ls— -> ['Or']\n",
            "giga-Ls— Or -> ['to']\n",
            "Or to -> ['gyatt']\n",
            "to gyatt -> ['against']\n",
            "gyatt against -> ['a']\n",
            "against a -> ['sea']\n",
            "a sea -> ['of']\n",
            "sea of -> ['L’s,']\n",
            "of L’s, -> ['And']\n",
            "L’s, And -> ['by']\n",
            "And by -> ['touching']\n",
            "by touching -> ['grass,']\n",
            "touching grass, -> ['end']\n",
            "grass, end -> ['them?']\n",
            "end them? -> ['No']\n",
            "them? No -> ['cap.']\n",
            "No cap. -> ['POV:']\n",
            "cap. POV: -> ['You’re']\n",
            "POV: You’re -> ['flexing']\n",
            "You’re flexing -> ['your']\n",
            "flexing your -> ['glow-up']\n",
            "your glow-up -> ['fit,']\n",
            "glow-up fit, -> ['but']\n",
            "fit, but -> ['your']\n",
            "but your -> ['sneaky']\n",
            "your sneaky -> ['link']\n",
            "sneaky link -> ['ghosted']\n",
            "link ghosted -> ['you']\n",
            "ghosted you -> ['mid-talking']\n",
            "you mid-talking -> ['stage.']\n",
            "mid-talking stage. -> ['Low-key']\n",
            "stage. Low-key -> ['feeling']\n",
            "Low-key feeling -> ['triggered,']\n",
            "feeling triggered, -> ['you']\n",
            "triggered, you -> ['hop']\n",
            "you hop -> ['on']\n",
            "hop on -> ['FYP,']\n",
            "on FYP, -> ['watching']\n",
            "FYP, watching -> ['main']\n",
            "watching main -> ['character']\n",
            "main character -> ['energy']\n",
            "character energy -> ['TikToks']\n",
            "energy TikToks -> ['While']\n",
            "TikToks While -> ['sipping']\n",
            "While sipping -> ['deconstructed']\n",
            "sipping deconstructed -> ['charcuterie-core']\n",
            "deconstructed charcuterie-core -> ['kombucha.']\n",
            "charcuterie-core kombucha. -> ['DMs']\n",
            "kombucha. DMs -> ['are']\n",
            "DMs are -> ['dry,']\n",
            "are dry, -> ['your']\n",
            "dry, your -> ['situationship']\n",
            "your situationship -> ['caught']\n",
            "situationship caught -> ['feelings,']\n",
            "caught feelings, -> ['and']\n",
            "feelings, and -> ['your']\n",
            "and your -> ['finsta', 'platonic']\n",
            "your finsta -> ['is']\n",
            "finsta is -> ['full']\n",
            "is full -> ['of']\n",
            "full of -> ['soft']\n",
            "of soft -> ['launch']\n",
            "soft launch -> ['pictures']\n",
            "launch pictures -> ['of']\n",
            "pictures of -> ['your']\n",
            "of your -> ['ex’s']\n",
            "your ex’s -> ['drip.']\n",
            "ex’s drip. -> ['Meanwhile,']\n",
            "drip. Meanwhile, -> ['in']\n",
            "Meanwhile, in -> ['the']\n",
            "in the -> ['metaverse,']\n",
            "the metaverse, -> ['your']\n",
            "metaverse, your -> ['NFT']\n",
            "your NFT -> ['rug-pulled,']\n",
            "NFT rug-pulled, -> ['so']\n",
            "rug-pulled, so -> ['you']\n",
            "so you -> ['hit']\n",
            "you hit -> ['a']\n",
            "hit a -> ['digital']\n",
            "a digital -> ['detox']\n",
            "digital detox -> ['and']\n",
            "detox and -> ['go']\n",
            "and go -> ['AFK—']\n",
            "go AFK— -> ['Only']\n",
            "AFK— Only -> ['to']\n",
            "Only to -> ['respawn']\n",
            "to respawn -> ['in']\n",
            "respawn in -> ['a']\n",
            "in a -> ['study']\n",
            "a study -> ['vlog']\n",
            "study vlog -> ['grind']\n",
            "vlog grind -> ['set,']\n",
            "grind set, -> ['fueled']\n",
            "set, fueled -> ['by']\n",
            "fueled by -> ['bulletproof']\n",
            "by bulletproof -> ['coffee']\n",
            "bulletproof coffee -> ['and']\n",
            "coffee and -> ['a']\n",
            "and a -> ['questionable']\n",
            "a questionable -> ['mukbang']\n",
            "questionable mukbang -> ['of']\n",
            "mukbang of -> ['plant-based']\n",
            "of plant-based -> ['sourdough']\n",
            "plant-based sourdough -> ['toast.']\n",
            "sourdough toast. -> ['The']\n",
            "toast. The -> ['algorithm']\n",
            "The algorithm -> ['decides']\n",
            "algorithm decides -> ['your']\n",
            "decides your -> ['whole']\n",
            "your whole -> ['life,']\n",
            "whole life, -> ['you']\n",
            "life, you -> ['get']\n",
            "you get -> ['an']\n",
            "get an -> ['L']\n",
            "an L -> ['in']\n",
            "L in -> ['your']\n",
            "in your -> ['GPA']\n",
            "your GPA -> ['flex,']\n",
            "GPA flex, -> ['and']\n",
            "flex, and -> ['your']\n",
            "your platonic -> ['bestie']\n",
            "platonic bestie -> ['benches']\n",
            "bestie benches -> ['you']\n",
            "benches you -> ['like']\n",
            "you like -> ['a']\n",
            "like a -> ['literal']\n",
            "a literal -> ['gym']\n",
            "literal gym -> ['bro.']\n",
            "gym bro. -> ['Gym']\n",
            "bro. Gym -> ['grind?']\n",
            "Gym grind? -> [\"Bussin'.\"]\n",
            "grind? Bussin'. -> ['Relationship?']\n",
            "Bussin'. Relationship? -> ['Mid.']\n",
            "Relationship? Mid. -> ['Cottagecore']\n",
            "Mid. Cottagecore -> ['escape?']\n",
            "Cottagecore escape? -> ['Vibing.']\n",
            "escape? Vibing. -> ['In']\n",
            "Vibing. In -> ['the']\n",
            "In the -> ['end,']\n",
            "the end, -> ['we']\n",
            "end, we -> ['are']\n",
            "we are -> ['all']\n",
            "are all -> ['just']\n",
            "all just -> ['NPCs']\n",
            "just NPCs -> ['in']\n",
            "NPCs in -> ['an']\n",
            "in an -> ['OP']\n",
            "an OP -> ['boss']\n",
            "OP boss -> ['fight,']\n",
            "boss fight, -> ['waiting']\n",
            "fight, waiting -> ['for']\n",
            "waiting for -> ['a']\n",
            "for a -> ['cultural']\n",
            "a cultural -> ['reset']\n",
            "cultural reset -> ['that']\n",
            "reset that -> ['never']\n",
            "that never -> ['comes.']\n",
            "never comes. -> ['No']\n",
            "comes. No -> ['cap,']\n",
            "No cap, -> ['just']\n",
            "cap, just -> ['vibes.']\n"
          ]
        }
      ],
      "source": [
        "# Sample text\n",
        "# Task 2: Add your own text here\n",
        "your_text = \"\"\"\n",
        "Skibidi rizz or not to rizz, that is the giga-chad question:\n",
        "Whether 'tis NPC-core to sigma through the ratioed slings and arrows\n",
        "Of outrageous fanum tax, cap, and giga-Ls—\n",
        "Or to gyatt against a sea of L’s,\n",
        "And by touching grass, end them? No cap.\n",
        "\n",
        "POV: You’re flexing your glow-up fit, but your sneaky link ghosted you mid-talking stage.\n",
        "Low-key feeling triggered, you hop on FYP, watching main character energy TikToks\n",
        "While sipping deconstructed charcuterie-core kombucha.\n",
        "DMs are dry, your situationship caught feelings, and your finsta is full of soft launch\n",
        "pictures of your ex’s drip.\n",
        "\n",
        "Meanwhile, in the metaverse, your NFT rug-pulled,\n",
        "so you hit a digital detox and go AFK—\n",
        "Only to respawn in a study vlog grind set, fueled by bulletproof coffee\n",
        "and a questionable mukbang of plant-based sourdough toast.\n",
        "\n",
        "The algorithm decides your whole life,\n",
        "you get an L in your GPA flex,\n",
        "and your platonic bestie benches you like a literal gym bro.\n",
        "Gym grind? Bussin'. Relationship? Mid.\n",
        "Cottagecore escape? Vibing.\n",
        "\n",
        "In the end, we are all just NPCs in an OP boss fight,\n",
        "waiting for a cultural reset that never comes.\n",
        "No cap, just vibes.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Build the chain\n",
        "chain = build_markov_chain(your_text)\n",
        "\n",
        "# Examine the chain\n",
        "for state, words in chain.items():\n",
        "    print(f\"{' '.join(state)} -> {words}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0X5R0dXbQD0R",
        "outputId": "91b7467f-b303-4f69-c38e-6999d6e27e15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text:\n",
            "grind set, fueled by bulletproof coffee and a questionable mukbang of plant-based sourdough toast. The algorithm decides your whole life, you get an L in your GPA flex, and your\n"
          ]
        }
      ],
      "source": [
        "# Generate some text\n",
        "print(\"Generated text:\")\n",
        "print(generate_text(chain))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64tghOmqQD0R"
      },
      "source": [
        "## Student Tasks\n",
        "\n",
        "1. Basic Implementation:\n",
        "   - Try changing the order parameter in build_markov_chain\n",
        "   - What happens with order=1 vs order=3?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0ytMH9g-QD0S",
        "outputId": "985b6bbe-e44e-43d8-a4a7-b7d07ad90132",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Order 1:\n",
            "go AFK— Only to respawn in your glow-up fit, but your glow-up fit, but your NFT rug-pulled, so you like a digital detox and your platonic bestie benches you mid-talking\n",
            "\n",
            "Order 3:\n",
            "and giga-Ls— Or to gyatt against a sea of L’s, And by touching grass, end them? No cap. POV: You’re flexing your glow-up fit, but your sneaky link ghosted you\n"
          ]
        }
      ],
      "source": [
        "# Task 1: Experiment with different orders\n",
        "print(\"\\nOrder 1:\")\n",
        "chain1 = build_markov_chain(your_text, order=1)\n",
        "print(generate_text(chain1))\n",
        "\n",
        "print(\"\\nOrder 3:\")\n",
        "chain3 = build_markov_chain(your_text, order=3)\n",
        "print(generate_text(chain3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8AyETF-QD0S"
      },
      "source": [
        "2. Use Your Own Text:\n",
        "   Below, try using a different text source. You could use:\n",
        "   - Song lyrics\n",
        "   - Book excerpts\n",
        "   - Movie quotes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GBn-xT5NQD0S"
      },
      "outputs": [],
      "source": [
        "# Task 2: Add your own text here\n",
        "your_text = \"\"\"\n",
        "[Replace this with your own text]\n",
        "Example:\n",
        "To be, or not to be, that is the question:\n",
        "Whether 'tis nobler in the mind to suffer\n",
        "The slings and arrows of outrageous fortune...\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FTQrQwDQD0S"
      },
      "source": [
        "3. Advanced Implementation:\n",
        "   Add temperature-based sampling to control randomness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LHhMkn2MQD0S",
        "outputId": "9ecc948d-c99b-4a31-b154-1509ed15e6a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Low temperature (more predictable):\n",
            "and go AFK— Only to respawn in a study vlog grind set, fueled by bulletproof coffee and a questionable mukbang of plant-based sourdough toast. The algorithm decides your whole life,\n",
            "\n",
            "High temperature (more random):\n",
            "fueled by bulletproof coffee and a questionable mukbang of plant-based sourdough toast. The algorithm decides your whole life, you get an L in your GPA flex, and your platonic bestie\n"
          ]
        }
      ],
      "source": [
        "def generate_text_with_temperature(chain, temperature=400, num_words=30):\n",
        "    \"\"\"\n",
        "    Generate text with temperature-based sampling.\n",
        "    Lower temperature = more conservative/predictable\n",
        "    Higher temperature = more random/creative\n",
        "\n",
        "    Args:\n",
        "        chain (dict): Markov chain\n",
        "        temperature (float): Controls randomness (0.1 to 2.0 recommended)\n",
        "        order (int): Length of state tuples\n",
        "        num_words (int): Number of words to generate\n",
        "    \"\"\"\n",
        "    words = list(random.choice(list(chain.keys())))\n",
        "    order = len(list(chain.keys())[0])\n",
        "\n",
        "    for _ in range(num_words - order):\n",
        "        state = tuple(words[-order:])\n",
        "        if state in chain:\n",
        "            # Count frequencies of next words\n",
        "            next_words = chain[state]\n",
        "            word_counts = defaultdict(int)\n",
        "            for word in next_words:\n",
        "                word_counts[word] += 1\n",
        "\n",
        "            # Apply temperature\n",
        "            weights = [count ** (1.0 / temperature) for count in word_counts.values()]\n",
        "            total = sum(weights)\n",
        "            weights = [w/total for w in weights]\n",
        "\n",
        "            # Choose next word based on weighted probabilities\n",
        "            next_word = random.choices(list(word_counts.keys()), weights=weights)[0]\n",
        "            words.append(next_word)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Try different temperatures\n",
        "print(\"\\nLow temperature (more predictable):\")\n",
        "print(generate_text_with_temperature(chain, temperature=0.3))\n",
        "\n",
        "print(\"\\nHigh temperature (more random):\")\n",
        "print(generate_text_with_temperature(chain, temperature=2.0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_r4UezdQD0S"
      },
      "source": [
        "## Challenge Tasks:\n",
        "\n",
        "1. Implement a function to analyze the Markov chain:\n",
        "   - Count the number of unique states\n",
        "   - Find the most common transitions\n",
        "   - Calculate the average number of possible next words for each state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hg9jgcEjQD0S",
        "outputId": "38359694-aca4-434f-913a-185de35f930e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Chain Analysis:\n",
            "Number of unique states: 20\n",
            "Average transitions per state: 1.30\n",
            "\n",
            "Most common transitions:\n",
            "The quick -> brown (count: 1)\n",
            "quick brown -> dog (count: 2)\n",
            "brown fox -> jumps (count: 1)\n",
            "fox jumps -> over (count: 1)\n",
            "jumps over -> the (count: 2)\n"
          ]
        }
      ],
      "source": [
        "def analyze_chain(chain):\n",
        "    \"\"\"\n",
        "    Analyze properties of the Markov chain.\n",
        "\n",
        "    Args:\n",
        "        chain (dict): Markov chain to analyze\n",
        "    \"\"\"\n",
        "    num_states = len(chain)\n",
        "    total_transitions = sum(len(next_words) for next_words in chain.values())\n",
        "    avg_transitions = total_transitions / num_states if num_states > 0 else 0\n",
        "\n",
        "    # Find most common next word for each state\n",
        "    most_common = {}\n",
        "    for state, next_words in chain.items():\n",
        "        word_counts = defaultdict(int)\n",
        "        for word in next_words:\n",
        "            word_counts[word] += 1\n",
        "        most_common[state] = max(word_counts.items(), key=lambda x: x[1])\n",
        "\n",
        "    print(f\"Number of unique states: {num_states}\")\n",
        "    print(f\"Average transitions per state: {avg_transitions:.2f}\")\n",
        "    print(\"\\nMost common transitions:\")\n",
        "    for state, (word, count) in list(most_common.items())[:5]:  # Show top 5\n",
        "        print(f\"{' '.join(state)} -> {word} (count: {count})\")\n",
        "\n",
        "# Analyze our chain\n",
        "print(\"\\nChain Analysis:\")\n",
        "analyze_chain(chain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zyFFvEFQD0S"
      },
      "source": [
        "## Further Exploration:\n",
        "\n",
        "Other ideas to try:\n",
        "1. Modify the code to preserve punctuation\n",
        "2. Add start-of-sentence and end-of-sentence tokens\n",
        "3. Implement bi-directional generation\n",
        "4. Create a chain that works with characters instead of words\n",
        "5. Add input validation and error handling"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "iat460",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}